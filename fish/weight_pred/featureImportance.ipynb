{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code is the study about feature importance of ESALQ experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from numpy import log\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from datetime import datetime, timedelta\n",
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index    peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  \\\n",
      "664  665.0  492.04               29.0                24.8                 8.0   \n",
      "665  666.0  454.02               27.0                23.0                 7.6   \n",
      "666  667.0  480.56               27.1                22.8                 7.5   \n",
      "667  668.0  412.75               25.7                22.0                 7.5   \n",
      "668  669.0  471.80               27.2                23.4                 7.4   \n",
      "669  670.0  382.79               25.4                21.5                 7.5   \n",
      "670  671.0  401.90               26.5                22.3                 7.2   \n",
      "671  672.0  441.98               27.8                23.4                 7.5   \n",
      "672  673.0  468.54               28.0                23.5                 7.8   \n",
      "673  674.0  418.14               26.3                22.2                 7.4   \n",
      "\n",
      "     altura  espessura       data  \n",
      "664     9.1        3.2 2024-06-12  \n",
      "665     9.0        3.2 2024-06-12  \n",
      "666     8.9        3.2 2024-06-12  \n",
      "667     8.2        3.2 2024-06-12  \n",
      "668     8.9        3.2 2024-06-12  \n",
      "669     8.5        3.2 2024-06-12  \n",
      "670     8.5        3.2 2024-06-12  \n",
      "671     8.7        3.2 2024-06-12  \n",
      "672     8.5        3.2 2024-06-12  \n",
      "673     8.5        3.1 2024-06-12  \n"
     ]
    }
   ],
   "source": [
    "#função para tratar campo data\n",
    "def parser(x):\n",
    "    return pd.datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "#Agora vamos importar nosso arquivo \n",
    "df = pd.read_excel('biometria.xlsx', sheet_name='Página1')\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2024-02-28T00:00:00.000000000', '2024-03-20T00:00:00.000000000',\n",
       "       '2024-04-10T00:00:00.000000000', '2024-05-02T00:00:00.000000000',\n",
       "       '2024-05-23T00:00:00.000000000', '2024-06-12T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.nunique(axis='columns')\n",
    "df['data'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['data']=='2024-02-28T00:00:00.000000000']\n",
    "df2=df[df['data']=='2024-03-20T00:00:00.000000000']\n",
    "df3=df[df['data']=='2024-04-10T00:00:00.000000000']\n",
    "df4=df[df['data']=='2024-05-02T00:00:00.000000000']\n",
    "df5=df[df['data']=='2024-05-23T00:00:00.000000000']\n",
    "df6=df[df['data']=='2024-06-12T00:00:00.000000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    \"\"\"\n",
    "    Drops the specified columns from the DataFrame and returns the resulting DataFrame.\n",
    "    Also prints the first few rows of the resulting DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame after dropping the specified columns.\n",
    "    \"\"\"\n",
    "    columns_to_drop = ['data', 'Index', 'espessura']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1 after dropping columns:\n",
      "    peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  altura\n",
      "0  51.45               14.3                12.2                 4.0     4.1\n",
      "1  37.15               12.4                10.9                 3.8     3.2\n",
      "2  47.26               13.7                11.2                 3.4     4.0\n",
      "3  36.67               12.9                11.1                 3.7     3.7\n",
      "4  45.48               13.2                11.3                 3.8     4.5\n",
      "DataFrame 2 after dropping columns:\n",
      "       peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  altura\n",
      "120  100.40              16.08               13.08                 4.4     5.4\n",
      "121   77.45              15.70               13.50                 4.2     5.1\n",
      "122   89.55              15.70               13.40                 4.2     5.1\n",
      "123   88.03              16.00               13.80                 4.1     5.3\n",
      "124   96.96              16.40               14.00                 4.3     5.5\n",
      "DataFrame 3 after dropping columns:\n",
      "       peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  altura\n",
      "240  108.25               17.5                15.0                 4.5     5.5\n",
      "241  141.25               18.7                16.0                 4.7     5.5\n",
      "242  117.52               18.3                15.4                 5.0     5.2\n",
      "243   93.47               16.3                14.0                 4.1     4.9\n",
      "244  150.21               19.6                16.3                 4.9     5.5\n",
      "DataFrame 4 after dropping columns:\n",
      "       peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  altura\n",
      "360  198.67               20.4                17.9                 5.6     6.1\n",
      "361  163.91               19.4                16.4                 5.3     5.5\n",
      "362  169.86               20.0                17.3                 5.3     5.7\n",
      "363  215.34               21.5                18.2                 6.0     5.6\n",
      "364  198.79               20.2                17.3                 6.0     6.5\n",
      "DataFrame 5 after dropping columns:\n",
      "       peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  altura\n",
      "478  331.10               24.0                20.3                 6.5     7.4\n",
      "479  321.86               24.0                19.9                 6.1     7.5\n",
      "480  370.72               25.7                21.4                 6.3     7.9\n",
      "481  305.61               23.6                19.7                 6.0     7.5\n",
      "482  341.69               25.1                20.8                 6.2     8.1\n",
      "DataFrame 6 after dropping columns:\n",
      "       peso  comprimento_Total  comprimento_Padrao  comprimento_Cabeca  altura\n",
      "595  290.58               23.4                19.8                 6.2     6.8\n",
      "596  282.74               23.5                20.3                 6.5     6.5\n",
      "597  285.64               24.3                20.8                 6.6     6.6\n",
      "598  290.22               24.3                20.3                 6.8     6.8\n",
      "599  349.84               25.9                21.5                 7.0     7.0\n"
     ]
    }
   ],
   "source": [
    "# List of DataFrames\n",
    "dataframes = [df1, df2, df3, df4, df5, df6]\n",
    "\n",
    "# Apply drop_columns function to each DataFrame in the list\n",
    "dropped_dataframes = [drop_columns(df) for df in dataframes]\n",
    "\n",
    "# Print the first few rows of each resulting DataFrame\n",
    "for i, df in enumerate(dropped_dataframes):\n",
    "    print(f\"DataFrame {i+1} after dropping columns:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATA for BLIND TEST\n",
    "#exp2= setup(data = data,  target = 'peso')\n",
    "\n",
    "#exp1= setup(data = df6,  target = 'peso')\n",
    "#best_model = exp1.compare_models(n_select=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#huber = exp1.create_model('huber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dashboard of pycaret\n",
    "#evaluate_model(huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(huber, plot = 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dashboard of pycaret\n",
    "#evaluate_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame 1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>11:26:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 \n",
       "                                                                 \n",
       "Initiated  . . . . . . . . . . . . . . . . . .           11:26:06\n",
       "Status     . . . . . . . . . . . . . . . . . .   Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Linear Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, MAE, MSE, RMSE, R2, RMSLE, MAPE, TT (Sec)]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188007b9cb084b0e85b927ad62818a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def automate_modeling(dataframes, target, models_dict):\n",
    "    results = {}\n",
    "    for i, df in enumerate(dataframes):\n",
    "        print(f\"Processing DataFrame {i+1}...\")\n",
    "        exp = setup(data=df, target=target, verbose=False)\n",
    "        best_model = compare_models(n_select=1)\n",
    "        bm_abbreviation = [abbr for name, abbr in models_dict.items() if best_model.__class__.__name__ in name]\n",
    "        \n",
    "        if bm_abbreviation:\n",
    "            bm = create_model(bm_abbreviation[0])\n",
    "            plot_model(bm, plot='feature')\n",
    "            results[f'df{i+1}'] = bm\n",
    "        else:\n",
    "            print(f\"No matching abbreviation found for the best model: {best_model.__class__.__name__}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "dataframes = dropped_dataframes\n",
    "target_column = 'peso'\n",
    "models_dict = {\n",
    "    'LinearRegression': 'lr',\n",
    "    'LassoRegression': 'lasso',\n",
    "    'RidgeRegression': 'ridge',\n",
    "    'ElasticNet': 'en',\n",
    "    'LeastAngleRegression': 'lar',\n",
    "    'LassoLeastAngleRegression': 'llar',\n",
    "    'OrthogonalMatchingPursuit': 'omp',\n",
    "    'BayesianRidge': 'br',\n",
    "    'AutomaticRelevanceDetermination': 'ard',\n",
    "    'PassiveAggressiveRegressor': 'par',\n",
    "    'RandomSampleConsensus': 'ransac',\n",
    "    'TheilSenRegressor': 'tr',\n",
    "    'HuberRegressor': 'huber',\n",
    "    'KernelRidge': 'kr',\n",
    "    'SupportVectorMachine': 'svm',\n",
    "    'KNeighborsRegressor': 'knn',\n",
    "    'DecisionTree': 'dt',\n",
    "    'RandomForest': 'rf',\n",
    "    'ExtraTreesRegressor': 'et',\n",
    "    'AdaBoostRegressor': 'ada',\n",
    "    'GradientBoosting': 'gbr',\n",
    "    'MultiLevelPerceptron': 'mlp',\n",
    "    'ExtremeGradientBoosting': 'xgboost',\n",
    "    'LightGradientBoosting': 'lightgbm',\n",
    "    'CatBoostRegressor': 'catboost'\n",
    "}\n",
    "\n",
    "# Call the function\n",
    "results = automate_modeling(dataframes, target_column, models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
